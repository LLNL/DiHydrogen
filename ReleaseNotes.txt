========================= Release Notes v0.3.0 =========================

API:

 - H2 added a thin GPU portability layer that supports CUDA and ROCm
   (HIP) programming environments.
 - Added a spdlog-based logging capability.
 - Added initial support for (sequential) tensors.

Performance optimizations:

Internal features:

 - MIOpen is supported as a backend for "DNN compute kernels" in
   DistConv.
 - DistConv is supported on ROCm systems.
 - Added support for Gitlab CI.
 - Support for DaCe convolution kernels in DistConv

Build system:

 - Several updates to support ROCm 5.*.
 - Requires CMake >= 3.21.
 - Requires ROCm 5, with the latest available minor release being
   STRONGLY recommended, when targeting ROCm-based platforms. The
   current packages we need in this stack are:
     -- HIP (host)
     -- hipCUB
     -- ROCm-SMI
     -- MIOpen
     -- ROC-tracer

Bug fixes:
 - Fixed a bug in kernel selection for batchnorm gradients in the case of
   overlap/strides.

Retired features:

========================= Release Notes v0.2.1 =========================

API:

Performance optimizations:

Internal features:
 - Updated to support the Aluminum v0.7 API
 - Aluminum is now only required when DistConv Legacy is enabled

Build system:
 - Require Aluminum v0.7.0

Bug fixes:

Retired features:

========================= Release Notes v0.2.0 =========================

API:

Performance optimizations:

Internal features:
 - Updated to support the Aluminum v0.5 API

Build system:
 - Require Aluminum v0.5.0

Bug fixes:

Retired features:



========================= Release Notes v0.1 =========================

Initial release of the DiHydrogen Distributed Tensor Library.

DiHydrogen is the second version of the Hydrogen fork of the
well-known distributed linear algebra library, Elemental. DiHydrogen
aims to be a basic distributed multilinear algebra interface with a
particular emphasis on the needs of the distributed machine learning
effort, LBANN.

API:

Performance optimizations:

Internal features:
 - Support for the DistConv legacy library
 - Added multi-dimensional tensor class
 - Added support for older CUDA architectures v3.0+
 - Use CUB for memory management
 - Support for point-to-point (P2P) library
 - Support for NVSHMEM halo exchange

DistConv Legacy:
 - batchnorm
 - channel-wise softmax
 - concat
 - convolution
 - deconv
 - leaky-relu
 - pooling
 - relu
 - slice
 - softmax

Build system:
 - Require C++14
 - Added support for cuDNN v8

Bug fixes:
 - Fixed build issues with GCC8

Retired features:
